import json
import pandas as pd
import os, sys
import random

# --- Configuration ---
# The name of the final file you will transfer to your training repo
FINAL_TRAINING_FILE = "setfit_training_data.json"

# List of ALL generated JSON files to merge
GENERATED_FILES = [
    "generated_data/intent1.json", 
    "generated_data/intent2.json", 
    "generated_data/intent3.json",
    "generated_data/intent4.json",  
    "generated_data/intent5.json"  
]
# NOTE: Assuming these files are in your current working directory or `generated_data/` 
# if you adjust the pathing. Since you said they are in the current dir, this list works.

def consolidate_new_datasets():
    """
    Loads samples from all generated intent files, merges them into a single list, 
    shuffles the list, and creates the final training data JSON file.
    """
    print("="*60)
    print("üöÄ CONSOLIDATING ALL GENERATED DATA FOR TRANSFER")
    print("="*60)
    
    all_samples = []
    total_new_samples = 0
    
    # 1. Load and Append Samples from all Generated Files
    for new_file in GENERATED_FILES:
        if os.path.exists(new_file):
            try:
                with open(new_file, 'r', encoding='utf-8') as f:
                    new_data = json.load(f)
                
                if isinstance(new_data, list):
                    all_samples.extend(new_data)
                    total_new_samples += len(new_data)
                    print(f"‚úÖ Appended {len(new_data)} samples from {new_file}")
                else:
                    print(f"‚ö†Ô∏è Warning: {new_file} did not contain a list of samples. Skipping.")
            except Exception as e:
                 print(f"‚ùå Error reading {new_file}: {e}. Skipping.")
        else:
            print(f"‚ö†Ô∏è Warning: File not found: {new_file}. Skipping.")
    
    if total_new_samples == 0:
        print("üõë No data was successfully loaded. Cannot create the final file.")
        return

    # 2. Shuffle the entire dataset (Crucial for SetFit)
    random.seed(42) # Ensure reproducible shuffling
    random.shuffle(all_samples)
    
    # 3. Create the final structured dictionary
    final_data_structure = {
        "metadata": "Synthetic data generated by Mistral-7B-Instruct for 5 SetFit intents.",
        "training_data": all_samples
    }
    
    # 4. Save the Final JSON File
    print(f"\nWriting merged data to {FINAL_TRAINING_FILE}...")
    with open(FINAL_TRAINING_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data_structure, f, indent=2) 
    
    # 5. Final Verification
    df_final = pd.DataFrame(all_samples)
    unique_intents = df_final['label'].nunique()
    
    print("\n--- ‚úÖ Consolidation Summary ---")
    print(f"Total Samples Generated and Saved: {total_new_samples}")
    print(f"Total Unique Intents: {unique_intents}")
    
    print("\nFINAL Intent Distribution:")
    print(df_final['label'].value_counts().sort_index())
    
    print(f"\nüéâ CONSOLIDATION COMPLETE! The file '{FINAL_TRAINING_FILE}' is ready to be moved to your training repo.")

if __name__ == "__main__":
    # Ensure all necessary libraries are imported
    try:
        import random
    except ImportError:
        print("Error: Please install the 'random' library.")
        sys.exit(1)
        
    consolidate_new_datasets()